{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b86cdfc8-018d-4378-a6ce-233c8f552e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 stories.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "# Define the folder path where your text files are located\n",
    "folder_path = '/Users/safdarabbas/Desktop/Safdar /deep learning/safdar/ss'\n",
    "# Initialize an empty list to hold the stories\n",
    "stories = []\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.txt'):  # Only process .txt files\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            story_text = file.read()\n",
    "            stories.append(story_text)\n",
    "\n",
    "# Check how many stories were loaded\n",
    "print(f\"Loaded {len(stories)} stories.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32c073f6-9402-4d90-b14f-fd4fbce046cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the adventure of the three garridebs arthur conan doyle it may have been a comedy or it may have been a tragedy it cost one man his reason it cost me a blood letting and it cost yet another man the penalties of the law yet there was certainly an element of comedy well you shall judge for yourselves i remember the date very well for it was in the same month that holmes refused a knighthood for services which may perhaps some day be described i only refer to the matter in passing for in my position of partner and confidant i am obliged to be particularly careful to avoid any indiscretion i repeat however that this enables me to fix the date which was the latter end of june 1902 shortly after the conclusion of the south african war holmes had spent several days in bed as was his habit from time to time but he emerged that morning with a long foolscap document in his hand and a twinkle of amusement in his austere gray eyes there is a chance for you to make some money friend watson said he \n"
     ]
    }
   ],
   "source": [
    "def clean_text(doc):\n",
    "    # Remove the title and author section (generalized for different titles)\n",
    "    doc = re.sub(r'^.*\\n\\s*.*\\n+', '', doc, flags=re.IGNORECASE)\n",
    "\n",
    "    # Remove everything below the dashed line\n",
    "    doc = re.sub(r'\\n[-]{10,}.*$', '', doc, flags=re.DOTALL)\n",
    "\n",
    "    # Remove special characters and digits\n",
    "    doc = re.sub(r'\\W', ' ', str(doc))\n",
    "\n",
    "    # Remove single characters (like 'a', 'b', etc.)\n",
    "    doc = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', doc)\n",
    "\n",
    "    # Replace multiple spaces with one space\n",
    "    doc = re.sub(r'\\s+', ' ', doc)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    doc = doc.lower()\n",
    "\n",
    "    return doc\n",
    "cleaned_txt=[]    \n",
    "for story in stories:    \n",
    "    cleaned_txt.append(clean_text(story))\n",
    "print(cleaned_txt[0][:1000])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a997755d-8849-47ba-a7e8-70862226a998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT TXT THE ADVENTURE OF THE THREE GARRIDEBS Arthur Conan Doyle It may have been a comedy, or it may have been a tragedy. It cost one man his reason, it cost me a blood-letting, and it cost yet another man the penalties of the law. Yet there was certainly an element of comedy. Well, you shall judge for yourselves. I remember the date very well, for it was in the same month that Holmes refused a knighthood for services which may perhaps some day be described. I only refer to the matter in passing, for in my position of partner and confidant I am obliged to be particularly careful to avoid any indiscretion. I repeat, however, that this enables me to fix the date, which was the latter end of June, 1902, shortly after the conclusion of the South African War. Holmes had spent several days in bed, as was his habit from time to time, but he emerged that morning with a long foolscap document in his hand and a twinkle of amusement in his austere gray eyes. \"There is a chance for you to make some money,\n",
      "summery THE ADVENTURE OF THE THREE GARRIDEBS Arthur Conan Doyle It may have been a comedy, or it may have been a tragedy. It cost one man his reason, it cost me a blood-letting, and it cost yet another man the penalties of the law. Yet there was certainly an element of comedy. Well, you shall judge for yourselves. I remember the date very well, for it was in the same month that Holmes refused a knighthood for services which may perhaps some day be described. I only refer to the matter in passing, for in my position of partner and\n"
     ]
    }
   ],
   "source": [
    "def get_summary_and_text(text, word_limit=100):\n",
    "    words = text.split()\n",
    "    summary = ' '.join(words[:word_limit])\n",
    "    input_text = ' '.join(words[0:])\n",
    "    return input_text, summary\n",
    "\n",
    "input_texts = []\n",
    "summaries = []\n",
    "\n",
    "for story in stories:\n",
    "    input_text, summary = get_summary_and_text(story)\n",
    "    input_texts.append(input_text)\n",
    "    summaries.append(summary)\n",
    "\n",
    "print('INPUT TXT',input_texts[0][:1000])\n",
    "print('summery',summaries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7e49c855-3081-4bce-a574-ed91fc52d43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 04:37:35.559795: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-01-06 04:37:35.560177: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-01-06 04:37:35.560596: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-01-06 04:37:35.609763: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-01-06 04:37:35.610118: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-01-06 04:37:35.610418: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-01-06 04:37:35.693019: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-01-06 04:37:35.693414: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-01-06 04:37:35.693782: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-01-06 04:37:35.743128: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-01-06 04:37:35.743460: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-01-06 04:37:35.743822: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-01-06 04:37:35.910737: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-01-06 04:37:35.911135: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-01-06 04:37:35.911616: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-01-06 04:37:35.961176: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-01-06 04:37:35.961548: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-01-06 04:37:35.961943: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step - loss: 7.7688\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 2s 1s/step - loss: 7.7638\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 2s 1s/step - loss: 7.7584\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 2s 1s/step - loss: 7.7521\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 2s 1s/step - loss: 7.7436\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 2s 1s/step - loss: 7.7316\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 2s 1s/step - loss: 7.7120\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 2s 1s/step - loss: 7.6757\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 2s 1s/step - loss: 7.5907\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 2s 1s/step - loss: 7.4114\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x16a0f4f40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 165ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 04:37:57.300037: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-01-06 04:37:57.300641: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-01-06 04:37:57.301009: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-01-06 04:37:57.374224: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-01-06 04:37:57.374628: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-01-06 04:37:57.375017: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 04:37:57.547476: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-01-06 04:37:57.547912: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-01-06 04:37:57.548320: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "Predicted Summary:  adventure adventure adventure adventure adventure adventure adventure adventure adventure adventure adventure adventure adventure adventure adventure me me me me me me well well well well or or or or or of of of of of \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(input_texts + summaries)\n",
    "\n",
    "start_token = \"<start>\"\n",
    "end_token = \"<end>\"\n",
    "if start_token not in tokenizer.word_index:\n",
    "    tokenizer.word_index[start_token] = len(tokenizer.word_index) + 1\n",
    "if end_token not in tokenizer.word_index:\n",
    "    tokenizer.word_index[end_token] = len(tokenizer.word_index) + 2\n",
    "\n",
    "tokenizer.word_index[\"<pad>\"] = 0\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 for padding token\n",
    "\n",
    "input_sequences = tokenizer.texts_to_sequences(input_texts)\n",
    "summary_sequences = tokenizer.texts_to_sequences(summaries)\n",
    "\n",
    "max_encoder_seq_length = max([len(seq) for seq in input_sequences])\n",
    "max_decoder_seq_length = max([len(seq) for seq in summary_sequences])\n",
    "\n",
    "encoder_input_seq = pad_sequences(input_sequences, maxlen=max_encoder_seq_length, padding=\"post\")\n",
    "decoder_input_seq = pad_sequences(summary_sequences, maxlen=max_decoder_seq_length, padding=\"post\")\n",
    "\n",
    "decoder_target_seq = np.zeros_like(decoder_input_seq)\n",
    "decoder_target_seq[:, :-1] = decoder_input_seq[:, 1:]\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_encoder_seq_length,))\n",
    "encoder_embedding = Embedding(input_dim=vocab_size, output_dim=64)(encoder_inputs)\n",
    "encoder_lstm = LSTM(64, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_decoder_seq_length,))\n",
    "decoder_embedding = Embedding(input_dim=vocab_size, output_dim=64)(decoder_inputs)\n",
    "decoder_lstm = LSTM(64, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "# Fully connected layer for prediction\n",
    "decoder_dense = Dense(vocab_size, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    [encoder_input_seq, decoder_input_seq], np.expand_dims(decoder_target_seq, axis=-1),\n",
    "    batch_size=1,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Encoder inference model\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder inference setup\n",
    "decoder_state_input_h = Input(shape=(64,))\n",
    "decoder_state_input_c = Input(shape=(64,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_embedding_inf = Embedding(input_dim=vocab_size, output_dim=64)(decoder_inputs_single)\n",
    "\n",
    "decoder_lstm_inf = LSTM(64, return_sequences=True, return_state=True)\n",
    "decoder_outputs_inf, state_h_inf, state_c_inf = decoder_lstm_inf(\n",
    "    decoder_embedding_inf, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states_inf = [state_h_inf, state_c_inf]\n",
    "\n",
    "decoder_outputs_inf = decoder_dense(decoder_outputs_inf)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs_single] + decoder_states_inputs,\n",
    "    [decoder_outputs_inf] + decoder_states_inf\n",
    ")\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input sequence to get the context vectors\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Initialize the target sequence with the start token\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    \n",
    "    # Ensure that the start token exists in the word index\n",
    "    start_token_index = tokenizer.word_index.get(start_token, None)\n",
    "    if start_token_index is None:\n",
    "        raise ValueError(f\"Start token '{start_token}' not found in tokenizer word index.\")\n",
    "    \n",
    "    target_seq[0, 0] = start_token_index  # Replace with your actual start token index\n",
    "\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    for _ in range(max_decoder_seq_length):\n",
    "        # Predict the next word\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Get the index of the most likely word\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = tokenizer.index_word.get(sampled_token_index, \"\")\n",
    "\n",
    "        # Append the word to the decoded sentence\n",
    "        decoded_sentence += \" \" + sampled_word\n",
    "\n",
    "        # Exit if the end token is predicted\n",
    "        if sampled_word == end_token or sampled_word == \"\":\n",
    "            break\n",
    "\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "input_seq = pad_sequences(\n",
    "    tokenizer.texts_to_sequences(['''he door had flown open and a huge negro had burst into the room. He\n",
    "     would have been a comic figure if he had not been terrific, for he\n",
    "     was dressed in a very loud gray check suit with a flowing\n",
    "     salmon-coloured tie. His broad face and flattened nose were thrust\n",
    "     forward, as his sullen dark eyes, with a smouldering gleam of malice\n",
    "     in them, turned from one of us to the other''']), maxlen=max_encoder_seq_length, padding=\"post\"\n",
    ")\n",
    "\n",
    "# Decode the sequence\n",
    "predicted_summary = decode_sequence(input_seq)\n",
    "print(\"Predicted Summary:\", predicted_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9657153-b50e-4976-8d15-77cfb3eef509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
